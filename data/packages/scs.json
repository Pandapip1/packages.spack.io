{
    "name": "scs",
    "aliases": [],
    "versions": [
        {
            "name": "2.1.1",
            "sha256": "0e20b91e8caf744b84aa985ba4e98cc7235ee33612b2bad2bf31ea5ad4e07d93"
        }
    ],
    "latest_version": "2.1.1",
    "build_system": "MakefilePackage",
    "conflicts": [
        {
            "name": "arch=windows-None-None",
            "spec": "build_system=makefile",
            "description": null
        }
    ],
    "variants": [
        {
            "name": "build_system",
            "default": "makefile",
            "description": "Build systems supported by the package"
        },
        {
            "name": "cuda",
            "default": false,
            "description": "Build with Cuda support"
        }
    ],
    "homepage": "https://github.com/cvxgrp/scs",
    "maintainers": [],
    "patches": [
        {
            "owner": "builtin.scs",
            "sha256": "314e53d7d97b6f010b98a2dacd85764a332001da1538e65102d84f25e2805760",
            "level": 1,
            "working_dir": ".",
            "reverse": false,
            "relative_path": "make_gpu.patch",
            "version": ""
        }
    ],
    "resources": [],
    "description": "A C package that solves convex cone problems via operator splitting\n",
    "dependencies": [
        {
            "name": "blas",
            "description": "XBLAS is a reference implementation for extra precision BLAS. XBLAS is a\nreference implementation for the dense and banded BLAS routines, along\nwith extended and mixed precision version. Extended precision is only\nused internally; input and output arguments remain the same as in the\nexisting BLAS. Extra precisions is implemented as double-double (i.e.,\n128-bit total, 106-bit significand). Mixed precision permits some\ninput/output arguments of different types (mixing real and complex) or\nprecisions (mixing single and double). This implementation is proof of\nconcept, and no attempt was made to optimize performance; performance\nshould be as good as straightforward but careful code written by hand."
        },
        {
            "name": "cuda",
            "description": "CUDA is a parallel computing platform and programming model invented by\nNVIDIA. It enables dramatic increases in computing performance by\nharnessing the power of the graphics processing unit (GPU). Note: This\npackage does not currently install the drivers necessary to run CUDA.\nThese will need to be installed manually. See:\nhttps://docs.nvidia.com/cuda/ for details."
        },
        {
            "name": "gmake",
            "description": "GNU Make is a tool which controls the generation of executables and\nother non-source files of a program from the program's source files."
        },
        {
            "name": "lapack",
            "description": "libflame is a portable library for dense matrix computations, providing\nmuch of the functionality present in LAPACK, developed by current and\nformer members of the Science of High-Performance Computing (SHPC) group\nin the Institute for Computational Engineering and Sciences at The\nUniversity of Texas at Austin. libflame includes a compatibility layer,\nlapack2flame, which includes a complete LAPACK implementation."
        }
    ],
    "dependent_to": []
}