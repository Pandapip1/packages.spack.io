{
    "name": "libcuml",
    "aliases": [],
    "versions": [
        {
            "name": "0.15.0",
            "sha256": "5c9c656ae4eaa94a426e07d7385fd5ea0e5dc7abff806af2941aee10d4ca99c7"
        }
    ],
    "build_system": "CMakePackage",
    "conflicts": [
        {
            "name": "+ipo",
            "spec": "^cmake@:3.8",
            "description": "+ipo is not supported by CMake < 3.9"
        }
    ],
    "variants": [
        {
            "name": "build_type",
            "default": "RelWithDebInfo",
            "description": "CMake build type"
        },
        {
            "name": "ipo",
            "default": false,
            "description": "CMake interprocedural optimization"
        }
    ],
    "homepage": "https://rapids.ai",
    "maintainers": [],
    "patches": [],
    "resources": [],
    "description": "cuML is a suite of libraries that implement machine learning algorithms\nand mathematical primitives functions that share compatible APIs with\nother RAPIDS projects.\n",
    "dependencies": [
        {
            "name": "cmake",
            "description": "A cross-platform, open-source build system. CMake is a family of tools\ndesigned to build, test and package software."
        },
        {
            "name": "zlib",
            "description": "A free, general-purpose, legally unencumbered lossless data-compression\nlibrary."
        },
        {
            "name": "libcudf",
            "description": "Built based on the Apache Arrow columnar memory format, cuDF is a GPU\nDataFrame library for loading, joining, aggregating, filtering, and\notherwise manipulating data."
        },
        {
            "name": "cuda",
            "description": "CUDA is a parallel computing platform and programming model invented by\nNVIDIA. It enables dramatic increases in computing performance by\nharnessing the power of the graphics processing unit (GPU). Note: This\npackage does not currently install the drivers necessary to run CUDA.\nThese will need to be installed manually. See:\nhttps://docs.nvidia.com/cuda/ for details."
        },
        {
            "name": "blas",
            "description": "XBLAS is a reference implementation for extra precision BLAS. XBLAS is a\nreference implementation for the dense and banded BLAS routines, along\nwith extended and mixed precision version. Extended precision is only\nused internally; input and output arguments remain the same as in the\nexisting BLAS. Extra precisions is implemented as double-double (i.e.,\n128-bit total, 106-bit significand). Mixed precision permits some\ninput/output arguments of different types (mixing real and complex) or\nprecisions (mixing single and double). This implementation is proof of\nconcept, and no attempt was made to optimize performance; performance\nshould be as good as straightforward but careful code written by hand."
        },
        {
            "name": "nccl",
            "description": "Optimized primitives for collective multi-GPU communication."
        },
        {
            "name": "treelite",
            "description": "Treelite is a model compiler for efficient deployment of decision tree\nensembles."
        },
        {
            "name": "googletest",
            "description": "Google test framework for C++. Also called gtest."
        },
        {
            "name": "libcumlprims",
            "description": "libcuMLPrims library"
        },
        {
            "name": "mpi",
            "description": "Mvapich2 is a High-Performance MPI Library for clusters with diverse\nnetworks (InfiniBand, Omni-Path, Ethernet/iWARP, and RoCE) and computing\nplatforms (x86 (Intel and AMD), ARM and OpenPOWER)"
        },
        {
            "name": "ucx",
            "description": "a communication library implementing high-performance messaging for\nMPI/PGAS frameworks"
        }
    ],
    "dependent_to": [
        {
            "name": "py-cuml",
            "description": "cuML is a suite of libraries that implement machine learning algorithms\nand mathematical primitives functions that share compatible APIs with\nother RAPIDS projects."
        }
    ]
}