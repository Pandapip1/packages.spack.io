{
    "name": "py-pandas",
    "aliases": [],
    "versions": [
        {
            "name": "2.1.0",
            "sha256": "62c24c7fc59e42b775ce0679cfa7b14a5f9bfb7643cfbe708c960699e05fb918"
        },
        {
            "name": "2.0.3",
            "sha256": "c02f372a88e0d17f36d3093a644c73cfc1788e876a7c4bcb4020a77512e2043c"
        },
        {
            "name": "2.0.2",
            "sha256": "dd5476b6c3fe410ee95926873f377b856dbc4e81a9c605a0dc05aaccc6a7c6c6"
        },
        {
            "name": "2.0.1",
            "sha256": "19b8e5270da32b41ebf12f0e7165efa7024492e9513fb46fb631c5022ae5709d"
        },
        {
            "name": "2.0.0",
            "sha256": "cda9789e61b44463c1c4fe17ef755de77bcd13b09ba31c940d20f193d63a5dc8"
        },
        {
            "name": "1.5.3",
            "sha256": "74a3fd7e5a7ec052f183273dc7b0acd3a863edf7520f5d3a1765c04ffdb3b0b1"
        },
        {
            "name": "1.5.2",
            "sha256": "220b98d15cee0b2cd839a6358bd1f273d0356bf964c1a1aeb32d47db0215488b"
        },
        {
            "name": "1.5.1",
            "sha256": "249cec5f2a5b22096440bd85c33106b6102e0672204abd2d5c014106459804ee"
        },
        {
            "name": "1.5.0",
            "sha256": "3ee61b881d2f64dd90c356eb4a4a4de75376586cd3c9341c6c0fcaae18d52977"
        },
        {
            "name": "1.4.4",
            "sha256": "ab6c0d738617b675183e5f28db32b5148b694ad9bba0a40c3ea26d96b431db67"
        },
        {
            "name": "1.4.3",
            "sha256": "2ff7788468e75917574f080cd4681b27e1a7bf36461fe968b49a87b5a54d007c"
        },
        {
            "name": "1.4.2",
            "sha256": "92bc1fc585f1463ca827b45535957815b7deb218c549b7c18402c322c7549a12"
        },
        {
            "name": "1.4.1",
            "sha256": "8db93ec98ac7cb5f8ac1420c10f5e3c43533153f253fe7fb6d891cf5aa2b80d2"
        },
        {
            "name": "1.4.0",
            "sha256": "cdd76254c7f0a1583bd4e4781fb450d0ebf392e10d3f12e92c95575942e37df5"
        },
        {
            "name": "1.3.5",
            "sha256": "1e4285f5de1012de20ca46b188ccf33521bff61ba5c5ebd78b4fb28e5416a9f1"
        },
        {
            "name": "1.3.4",
            "sha256": "a2aa18d3f0b7d538e21932f637fbfe8518d085238b429e4790a35e1e44a96ffc"
        },
        {
            "name": "1.3.3",
            "sha256": "272c8cb14aa9793eada6b1ebe81994616e647b5892a370c7135efb2924b701df"
        },
        {
            "name": "1.3.2",
            "sha256": "cbcb84d63867af3411fa063af3de64902665bb5b3d40b25b2059e40603594e87"
        },
        {
            "name": "1.3.1",
            "sha256": "341935a594db24f3ff07d1b34d1d231786aa9adfa84b76eab10bf42907c8aed3"
        },
        {
            "name": "1.3.0",
            "sha256": "c554e6c9cf2d5ea1aba5979cc837b3649539ced0e18ece186f055450c86622e2"
        },
        {
            "name": "1.2.5",
            "sha256": "14abb8ea73fce8aebbb1fb44bec809163f1c55241bcc1db91c2c780e97265033"
        },
        {
            "name": "1.2.4",
            "sha256": "649ecab692fade3cbfcf967ff936496b0cfba0af00a55dfaacd82bdda5cb2279"
        },
        {
            "name": "1.2.3",
            "sha256": "df6f10b85aef7a5bb25259ad651ad1cc1d6bb09000595cab47e718cbac250b1d"
        },
        {
            "name": "1.2.2",
            "sha256": "14ed84b463e9b84c8ff9308a79b04bf591ae3122a376ee0f62c68a1bd917a773"
        },
        {
            "name": "1.2.1",
            "sha256": "5527c5475d955c0bc9689c56865aaa2a7b13c504d6c44f0aadbf57b565af5ebd"
        },
        {
            "name": "1.2.0",
            "sha256": "e03386615b970b8b41da6a68afe717626741bb2431cec993640685614c0680e4"
        },
        {
            "name": "1.1.5",
            "sha256": "f10fc41ee3c75a474d3bdf68d396f10782d013d7f67db99c0efbfd0acb99701b"
        },
        {
            "name": "1.1.4",
            "sha256": "a979d0404b135c63954dea79e6246c45dd45371a88631cdbb4877d844e6de3b6"
        },
        {
            "name": "1.1.3",
            "sha256": "babbeda2f83b0686c9ad38d93b10516e68cdcd5771007eb80a763e98aaf44613"
        },
        {
            "name": "1.1.2",
            "sha256": "b64ffd87a2cfd31b40acd4b92cb72ea9a52a48165aec4c140e78fd69c45d1444"
        },
        {
            "name": "1.1.1",
            "sha256": "53328284a7bb046e2e885fd1b8c078bd896d7fc4575b915d4936f54984a2ba67"
        },
        {
            "name": "1.1.0",
            "sha256": "b39508562ad0bb3f384b0db24da7d68a2608b9ddc85b1d931ccaaa92d5e45273"
        },
        {
            "name": "1.0.5",
            "sha256": "69c5d920a0b2a9838e677f78f4dde506b95ea8e4d30da25859db6469ded84fa8"
        },
        {
            "name": "1.0.4",
            "sha256": "b35d625282baa7b51e82e52622c300a1ca9f786711b2af7cbe64f1e6831f4126"
        },
        {
            "name": "1.0.3",
            "sha256": "32f42e322fb903d0e189a4c10b75ba70d90958cc4f66a1781ed027f1a1d14586"
        },
        {
            "name": "1.0.2",
            "sha256": "76334ba36aa42f93b6b47b79cbc32187d3a178a4ab1c3a478c8f4198bcd93a73"
        },
        {
            "name": "1.0.1",
            "sha256": "3c07765308f091d81b6735d4f2242bb43c332cc3461cae60543df6b10967fe27"
        },
        {
            "name": "1.0.0",
            "sha256": "3ea6cc86931f57f18b1240572216f09922d91b19ab8a01cf24734394a3db3bec"
        },
        {
            "name": "0.25.3",
            "sha256": "52da74df8a9c9a103af0a72c9d5fdc8e0183a90884278db7f386b5692a2220a4"
        },
        {
            "name": "0.25.2",
            "sha256": "ca91a19d1f0a280874a24dca44aadce42da7f3a7edb7e9ab7c7baad8febee2be"
        },
        {
            "name": "0.25.1",
            "sha256": "cb2e197b7b0687becb026b84d3c242482f20cbb29a9981e43604eb67576da9f6"
        },
        {
            "name": "0.25.0",
            "sha256": "914341ad2d5b1ea522798efa4016430b66107d05781dbfe7cf05eba8f37df995"
        },
        {
            "name": "0.24.2",
            "sha256": "4f919f409c433577a501e023943e582c57355d50a724c589e78bc1d551a535a2"
        },
        {
            "name": "0.24.1",
            "sha256": "435821cb2501eabbcee7e83614bd710940dc0cf28b5afbc4bdb816c31cec71af"
        },
        {
            "name": "0.23.4",
            "sha256": "5b24ca47acf69222e82530e89111dd9d14f9b970ab2cd3a1c2c78f0c4fbba4f4"
        }
    ],
    "latest_version": "2.1.0",
    "build_system": "PythonPackage",
    "conflicts": [],
    "variants": [
        {
            "name": "build_system",
            "default": "python_pip",
            "description": "Build systems supported by the package"
        }
    ],
    "homepage": "https://pandas.pydata.org/",
    "maintainers": [
        "adamjstewart"
    ],
    "patches": [],
    "resources": [],
    "description": "pandas is a fast, powerful, flexible and easy to use open source data\nanalysis and manipulation tool, built on top of the Python programming\nlanguage.\n",
    "dependencies": [
        {
            "name": "python",
            "description": "The Python programming language."
        },
        {
            "name": "py-pip",
            "description": "The PyPA recommended tool for installing Python packages."
        },
        {
            "name": "py-wheel",
            "description": "A built-package format for Python."
        },
        {
            "name": "py-meson-python",
            "description": "Meson Python build backend (PEP 517)."
        },
        {
            "name": "meson",
            "description": "Meson is a portable open source build system meant to be both extremely\nfast, and as user friendly as possible."
        },
        {
            "name": "py-cython",
            "description": "The Cython compiler for writing C extensions for the Python language."
        },
        {
            "name": "py-versioneer",
            "description": "Versioneer is a tool to automatically update version strings by asking\nyour version-control system about the current tree."
        },
        {
            "name": "py-numpy",
            "description": "NumPy is the fundamental package for scientific computing with Python.\nIt contains among other things: a powerful N-dimensional array object,\nsophisticated (broadcasting) functions, tools for integrating C/C++ and\nFortran code, and useful linear algebra, Fourier transform, and random\nnumber capabilities"
        },
        {
            "name": "py-python-dateutil",
            "description": "Extensions to the standard Python datetime module."
        },
        {
            "name": "py-pytz",
            "description": "World timezone definitions, modern and historical."
        },
        {
            "name": "py-tzdata",
            "description": "Provider of IANA time zone data."
        },
        {
            "name": "py-numexpr",
            "description": "Fast numerical expression evaluator for NumPy"
        },
        {
            "name": "py-bottleneck",
            "description": "A collection of fast NumPy array functions written in Cython."
        },
        {
            "name": "py-numba",
            "description": "NumPy aware dynamic Python compiler using LLVM"
        },
        {
            "name": "py-setuptools",
            "description": "A Python utility that aids in the process of downloading, building,\nupgrading, installing, and uninstalling Python packages."
        }
    ],
    "dependent_to": [
        {
            "name": "py-workload-automation",
            "description": "Workload Automation (WA) is a framework for executing workloads and\ncollecting measurements on Android and Linux devices."
        },
        {
            "name": "py-alpaca-farm",
            "description": "AlpacaFarm is a simulator that enables research and development on\nlearning from feedback at a fraction of the usual cost, promoting\naccessible research on instruction following and alignment."
        },
        {
            "name": "py-kb-python",
            "description": "Python wrapper around kallisto | bustools for scRNA-seq analysis."
        },
        {
            "name": "py-wub",
            "description": "Bioinformatics tools and a software library developed by the Oxford\nNanopore Technologies Applications group."
        },
        {
            "name": "openturns",
            "description": "OpenTURNS is a scientific C++ and Python library featuring an internal\ndata model and algorithms dedicated to the treatment of uncertainties.\nThe main goal of this library is to provide all functionalities needed\nto treat uncertainties in studies with industrial applications. Targeted\nusers are all engineers who want to introduce the probabilistic\ndimension in their so far deterministic studies."
        },
        {
            "name": "py-amici",
            "description": "Advanced Multilanguage Interface for CVODES and IDAS"
        },
        {
            "name": "py-fastai",
            "description": "You can use fastai without any installation by using Google Colab. In\nfact, every page of this documentation is also available as an\ninteractive notebook - click \"Open in colab\" at the top of any page to\nopen it (be sure to change the Colab runtime to \"GPU\" to have it run\nfast!) See the fast.ai documentation on Using Colab for more\ninformation."
        },
        {
            "name": "py-topiary-asr",
            "description": "Python framework for doing ancestral sequence reconstruction."
        },
        {
            "name": "py-pybobyqa",
            "description": "Py-BOBYQA is a flexible package for solving bound-constrained general\nobjective minimization, without requiring derivatives of the objective."
        },
        {
            "name": "py-goatools",
            "description": "Python scripts to find enrichment of GO terms"
        },
        {
            "name": "py-xarray",
            "description": "N-D labeled arrays and datasets in Python"
        },
        {
            "name": "cosmomc",
            "description": "CosmoMC is a Fortran 2008 Markov-Chain Monte-Carlo (MCMC) engine for\nexploring cosmological parameter space, together with Fortran and python\ncode for analysing Monte-Carlo samples and importance sampling (plus a\nsuite of scripts for building grids of runs, plotting and presenting\nresults)."
        },
        {
            "name": "py-motmetrics",
            "description": "The py-motmetrics library provides a Python implementation of metrics\nfor benchmarking multiple object trackers (MOT)."
        },
        {
            "name": "py-antspyx",
            "description": "Advanced Normalization Tools in Python."
        },
        {
            "name": "py-damask",
            "description": "Pre- and post-processing tools for DAMASK"
        },
        {
            "name": "py-scanpy",
            "description": "Scanpy is a scalable toolkit for analyzing single-cell gene expression\ndata built jointly with anndata."
        },
        {
            "name": "py-dask",
            "description": "Dask is a flexible parallel computing library for analytics."
        },
        {
            "name": "py-shap",
            "description": "SHAP (SHapley Additive exPlanations): a unified approach to explain the\noutput of any machine learning model."
        },
        {
            "name": "py-devito",
            "description": "Devito is a Python package to implement optimized stencil computation.\n(e.g., finite differences, image processing, machine learning) from\nhigh-level symbolic problem definitions. Devito builds on SymPy and\nemploys automated code generation and just-in-time compilation to\nexecute optimized computational kernels on several computer platforms,\nincluding CPUs, GPUs, and clusters thereof."
        },
        {
            "name": "py-plotnine",
            "description": "plotnine is an implementation of a grammar of graphics in Python, it is\nbased on ggplot2. The grammar allows users to compose plots by\nexplicitly mapping data to the visual objects that make up the plot."
        },
        {
            "name": "py-gradio",
            "description": "Python library for easily interacting with trained machine learning\nmodels"
        },
        {
            "name": "py-umi-tools",
            "description": "Tools for handling Unique Molecular Identifiers in NGS data sets"
        },
        {
            "name": "py-correctionlib",
            "description": "A generic correction library"
        },
        {
            "name": "py-dask-ml",
            "description": "Scalable Machine Learning with Dask."
        },
        {
            "name": "cosmoflow-benchmark",
            "description": "This is a an implementation of the CosmoFlow 3D convolutional neural\nnetwork for benchmarking. It is written in TensorFlow with the Keras API\nand uses Horovod for distributed training."
        },
        {
            "name": "pharokka",
            "description": "pharokka is a rapid standardised annotation pipeline for bacteriophage\ngenomes"
        },
        {
            "name": "py-pubchempy",
            "description": "PubChemPy provides a way to interact with PubChem in Python. It allows\nchemical searches by name, substructure and similarity, chemical\nstandardization, conversion between chemical file formats, depiction and\nretrieval of chemical properties."
        },
        {
            "name": "py-modin",
            "description": "Modin: Make your pandas code run faster by changing one line of code."
        },
        {
            "name": "py-datasets",
            "description": "Datasets is a lightweight library providing two main features: one-line\ndataloaders for many public datasets and efficient data pre-processing."
        },
        {
            "name": "py-pathml",
            "description": "An open-source toolkit for computational pathology and machine learning."
        },
        {
            "name": "py-abipy",
            "description": "Python package to automate ABINIT calculations and analyze the results."
        },
        {
            "name": "py-darshan",
            "description": "Python utilities to interact with Darshan log records of HPC\napplications."
        },
        {
            "name": "py-alpaca-eval",
            "description": "An automatic evaluator for instruction-following language models. Human-\nvalidated, high-quality, cheap, and fast."
        },
        {
            "name": "py-rdt",
            "description": "RDT is a Python library used to transform data for data science\nlibraries and preserve the transformations in order to revert them as\nneeded."
        },
        {
            "name": "py-pipits",
            "description": "Automated pipeline for analyses of fungal ITS from the Illumina"
        },
        {
            "name": "py-nibetaseries",
            "description": "BetaSeries Correlations implemented in Nipype."
        },
        {
            "name": "py-ultralytics",
            "description": "Ultralytics YOLOv8, developed by Ultralytics, is a cutting-edge, state-\nof-the-art (SOTA) model that builds upon the success of previous YOLO\nversions and introduces new features and improvements to further boost\nperformance and flexibility. YOLOv8 is designed to be fast, accurate,\nand easy to use, making it an excellent choice for a wide range of\nobject detection, image segmentation and image classification tasks."
        },
        {
            "name": "portcullis",
            "description": "PORTable CULLing of Invalid Splice junctions"
        },
        {
            "name": "py-kosh",
            "description": "Kosh allows codes to store, query, share data via an easy-to-use Python\nAPI. Kosh lies on top of Sina and can use any database backend supported\nby Sina. In adition Kosh aims to make data access and sharing as simple\nas possible."
        },
        {
            "name": "py-hep-ml",
            "description": "Machine Learning for High Energy Physics"
        },
        {
            "name": "py-tbparse",
            "description": "Load tensorboard event logs as pandas DataFrames."
        },
        {
            "name": "hicops",
            "description": "HiCOPS is a software framework for accelerating database peptide search\nworkflows on supercomputers. HiCOPS provided algorithm-independent\nparallelizations and optimizations can be extended into new HPC database\nsearch algorithms or scalably accelerate the existing ones."
        },
        {
            "name": "py-bidscoin",
            "description": "Converts and organises raw MRI data-sets according to the Brain Imaging\nData Structure (BIDS)."
        },
        {
            "name": "py-mlflow",
            "description": "MLflow: A Platform for ML Development and Productionization."
        },
        {
            "name": "py-cudf",
            "description": "Built based on the Apache Arrow columnar memory format, cuDF is a GPU\nDataFrame library for loading, joining, aggregating, filtering, and\notherwise manipulating data."
        },
        {
            "name": "py-torch-geometric",
            "description": "PyTorch Geometric (PyG) is a geometric deep learning extension library\nfor PyTorch. It consists of various methods for deep learning on graphs\nand other irregular structures, also known as geometric deep learning,\nfrom a variety of published papers. In addition, it consists of an easy-\nto-use mini-batch loader for many small and single giant graphs, multi\ngpu-support, a large number of common benchmark datasets (based on\nsimple interfaces to create your own), and helpful transforms, both for\nlearning on arbitrary graphs as well as on 3D meshes or point clouds."
        },
        {
            "name": "py-continuum",
            "description": "A clean and simple data loading library for Continual Learning"
        },
        {
            "name": "py-nexusforge",
            "description": "Blue Brain Nexus Forge is a domain-agnostic, generic and extensible\nPython framework enabling non-expert users to create and manage\nknowledge graphs."
        },
        {
            "name": "dxt-explorer",
            "description": "DXT Explorer is an interactive web-based log analysis tool to visualize\nDarshan DXT logs and help understand the I/O behavior of applications."
        },
        {
            "name": "py-streamlit",
            "description": "The fastest way to build data apps in Python."
        },
        {
            "name": "timemory",
            "description": "Modular profiling toolkit and suite of libraries and tools for\nC/C++/Fortran/CUDA/Python"
        },
        {
            "name": "py-mlxtend",
            "description": "Mlxtend (machine learning extensions) is a Python library of useful\ntools for the day-to-day data science tasks."
        },
        {
            "name": "py-formulaic",
            "description": "Formulaic is a high-performance implementation of Wilkinson formulas for\nPython."
        },
        {
            "name": "py-hypothesis",
            "description": "A library for property based testing."
        },
        {
            "name": "py-phydms",
            "description": "phydms enables phylogenetic analyses using deep mutational scanning data\nto inform the substitution models. It implements Experimentally informed\ncodon models (ExpCM) for phylogenetic inference and the detection of\nbiologically interesting selection."
        },
        {
            "name": "py-ctgan",
            "description": "CTGAN is a collection of Deep Learning based Synthetic Data Generators\nfor single table data, which are able to learn from real data and\ngenerate synthetic clones with high fidelity."
        },
        {
            "name": "py-devlib",
            "description": "Library for interaction with and instrumentation of remote devices."
        },
        {
            "name": "py-metpy",
            "description": "Collection of tools for reading, visualizing and performing calculations\nwith weather data."
        },
        {
            "name": "prmon",
            "description": "Standalone monitor for process resource consumption."
        },
        {
            "name": "py-openai",
            "description": "The OpenAI Python library provides convenient access to the OpenAI API\nfrom applications written in the Python language. It includes a pre-\ndefined set of classes for API resources that initialize themselves\ndynamically from API responses which makes it compatible with a wide\nrange of versions of the OpenAI API."
        },
        {
            "name": "paraview",
            "description": "ParaView is an open-source, multi-platform data analysis and\nvisualization application. This package includes the Catalyst in-situ\nlibrary for versions 5.7 and greater, otherwise use the catalyst\npackage."
        },
        {
            "name": "py-seaborn",
            "description": "Seaborn: statistical data visualization. Seaborn is a library for making\nattractive and informative statistical graphics in Python. It is built\non top of matplotlib and tightly integrated with the PyData stack,\nincluding support for numpy and pandas data structures and statistical\nroutines from scipy and statsmodels."
        },
        {
            "name": "parsec",
            "description": "PaRSEC: the Parallel Runtime Scheduler and Execution Controller PaRSEC\nis a runtime and a programming toolbox that support the design and\nparallel execution of micro-tasks on distributed, heterogeneous systems."
        },
        {
            "name": "py-tpot",
            "description": "A Python Automated Machine Learning tool that optimizes machine\nlearning pipelines using genetic programming."
        },
        {
            "name": "py-arviz",
            "description": "ArviZ (pronounced \"AR-vees\") is a Python package for exploratory\nanalysis of Bayesian models. Includes functions for posterior analysis,\nmodel checking, comparison and diagnostics."
        },
        {
            "name": "py-imbalanced-learn",
            "description": "imbalanced-learn is a python package offering a number of re-sampling\ntechniques commonly used in datasets showing strong between-class\nimbalance. It is compatible with scikit-learn and is part of scikit-\nlearn-contrib projects."
        },
        {
            "name": "py-arm-pyart",
            "description": "Python ARM Radar Toolkit. A growing collection of weather radar\nalgorithms and utilities build on top of the Scientific Python stack and\ndistributed under the 3-Clause BSD license. Py-ART is used by the\nAtmospheric Radiation Measurement (ARM) Climate Research Facility for\nworking with data from a number of precipitation and cloud radars, but\nhas been designed so that it can be used by others in the radar and\natmospheric communities to examine, processes, and analyse data from\nmany types of weather radars."
        },
        {
            "name": "py-panedr",
            "description": "Panedr uses the Pyedr library to read a Gromacs EDR binary energy XDR\nfile and returns its contents as a pandas dataframe"
        },
        {
            "name": "drishti",
            "description": "Drishti is a command-line tool to guide end-users in optimizing I/O in\ntheir applications by detecting typical I/O performance pitfalls and\nproviding a set of recommendations."
        },
        {
            "name": "py-copulas",
            "description": "Copulas is a Python library for modeling multivariate distributions and\nsampling from them using copula functions. Given a table containing\nnumerical data, we can use Copulas to learn the distribution and later\non generate new synthetic rows following the same statistical\nproperties."
        },
        {
            "name": "py-netpyne",
            "description": "Netpyne: A python package to facilitate the development, parallel\nsimulation, optimization and analysis of multiscale biological neuronal\nnetworks in NEURON."
        },
        {
            "name": "py-labours",
            "description": "Python module dependency visualization."
        },
        {
            "name": "py-pybedtools",
            "description": "Python wrapper -- and more -- for Aaron Quinlan's BEDTools"
        },
        {
            "name": "py-hatchet",
            "description": "Hatchet is a performance tool for analyzing hierarchical performance\ndata using a graph-indexed Pandas dataframe."
        },
        {
            "name": "py-biopandas",
            "description": "Working with molecular structures in pandas DataFrames"
        },
        {
            "name": "py-hclust2",
            "description": "Hclust2 is a handy tool for plotting heat-maps with several useful\noptions to produce high quality figures that can be used in publication."
        },
        {
            "name": "py-histogrammar",
            "description": "Composable histogram primitives for distributed data reduction."
        },
        {
            "name": "py-torchgeo",
            "description": "TorchGeo: datasets, samplers, transforms, and pre-trained models for\ngeospatial data. TorchGeo is a PyTorch domain library, similar to\ntorchvision, providing datasets, samplers, transforms, and pre-trained\nmodels specific to geospatial data."
        },
        {
            "name": "py-gluoncv",
            "description": "GluonCV provides implementations of state-of-the-art (SOTA) deep\nlearning algorithms in computer vision. It aims to help engineers,\nresearchers, and students quickly prototype products, validate new ideas\nand learn computer vision."
        },
        {
            "name": "py-nistats",
            "description": "Modeling and Statistical analysis of fMRI data in Python."
        },
        {
            "name": "py-piper",
            "description": "A lightweight python toolkit for gluing together restartable, robust\nshell pipelines."
        },
        {
            "name": "mlpack",
            "description": "mlpack is an intuitive, fast, and flexible header-only C++ machine\nlearning library with bindings to other languages. It is meant to be a\nmachine learning analog to LAPACK, and aims to implement a wide array of\nmachine learning methods and functions as a \"swiss army knife\" for\nmachine learning researchers."
        },
        {
            "name": "py-ucsf-pyem",
            "description": "UCSF pyem is a collection of Python modules and command-line utilities\nfor electron microscopy of biological samples."
        },
        {
            "name": "py-mne",
            "description": "MNE python project for MEG and EEG data analysis."
        },
        {
            "name": "py-deepecho",
            "description": "DeepEcho is a Synthetic Data Generation Python library for mixed-type,\nmultivariate time series."
        },
        {
            "name": "py-openmim",
            "description": "MIM Installs OpenMMLab packages"
        },
        {
            "name": "py-datalad-neuroimaging",
            "description": "DataLad extension package for neuro/medical imaging"
        },
        {
            "name": "py-deepsig",
            "description": "deep-significance: Easy and Better Significance Testing for Deep Neural\nNetworks"
        },
        {
            "name": "py-convokit",
            "description": "This toolkit contains tools to extract conversational features and\nanalyze social phenomena in conversations, using a single unified\ninterface inspired by (and compatible with) scikit-learn."
        },
        {
            "name": "py-geoplot",
            "description": "geoplot is a high-level Python geospatial plotting library. It's an\nextension to cartopy and matplotlib which makes mapping easy: like\nseaborn for geospatial."
        },
        {
            "name": "py-fastfold",
            "description": "Optimizing Protein Structure Prediction Model Training and Inference on\nGPU Clusters."
        },
        {
            "name": "py-ogb",
            "description": "The Open Graph Benchmark (OGB) is a collection of benchmark datasets,\ndata loaders, and evaluators for graph machine learning. Datasets cover\na variety of graph machine learning tasks and real-world applications.\nThe OGB data loaders are fully compatible with popular graph deep\nlearning frameworks, including PyTorch Geometric and Deep Graph Library\n(DGL). They provide automatic dataset downloading, standardized dataset\nsplits, and unified performance evaluation."
        },
        {
            "name": "py-networkx",
            "description": "NetworkX is a Python package for the creation, manipulation, and study\nof the structure, dynamics, and functions of complex networks."
        },
        {
            "name": "py-bmtk",
            "description": "The Brain Modeling Toolkit"
        },
        {
            "name": "callflow",
            "description": "CallFlow is an interactive visual analysis tool that provides a high-\nlevel overview of CCTs together with semantic refinement operations to\nprogressively explore the CCTs."
        },
        {
            "name": "py-fitter",
            "description": "fitter package provides a simple class to identify the distribution from\nwhich a data samples is generated from. It uses 80 distributions from\nScipy and allows you to plot the results to check what is the most\nprobable distribution and the best parameters."
        },
        {
            "name": "py-parsl",
            "description": "Simple data dependent workflows in Python"
        },
        {
            "name": "py-metaphlan",
            "description": "MetaPhlAn is a computational tool for profiling the composition of\nmicrobial communities (Bacteria, Archaea and Eukaryotes) from\nmetagenomic shotgun sequencing data (i.e. not 16S) with species-level."
        },
        {
            "name": "py-river",
            "description": "River is a Python library for online machine learning. It aims to be the\nmost user-friendly library for doing machine learning on streaming data.\nRiver is the result of a merge between creme and scikit-multiflow."
        },
        {
            "name": "py-drep",
            "description": "dRep is a python program for rapidly comparing large numbers of genomes.\ndRep can also \"de-replicate\" a genome set by identifying groups of\nhighly similar genomes and choosing the best representative genome for\neach genome set."
        },
        {
            "name": "py-mapclassify",
            "description": "Classification Schemes for Choropleth Maps."
        },
        {
            "name": "py-instrain",
            "description": "inStrain is python program for analysis of co-occurring genome\npopulations from metagenomes that allows highly accurate genome\ncomparisons, analysis of coverage, microdiversity, and linkage, and\nsensitive SNP detection with gene localization and synonymous non-\nsynonymous identification."
        },
        {
            "name": "py-pymc3",
            "description": "PyMC3 is a Python package for Bayesian statistical modeling and\nProbabilistic Machine Learning focusing on advanced Markov chain Monte\nCarlo (MCMC) and variational inference (VI) algorithms. Its flexibility\nand extensibility make it applicable to a large suite of problems."
        },
        {
            "name": "py-pastml",
            "description": "Ancestral character reconstruction and visualisation for rooted\nphylogenetic trees."
        },
        {
            "name": "py-deephyper",
            "description": "Scalable asynchronous neural architecture and hyperparameter search for\ndeep neural networks."
        },
        {
            "name": "reditools",
            "description": "REDItools: python scripts for RNA editing detection by RNA-Seq data.\nREDItools are simple python scripts conceived to facilitate the\ninvestigation of RNA editing at large-scale and devoted to research\ngroups that would to explore such phenomenon in own data but don't have\nsufficient bioinformatics skills. They work on main operating systems\n(although unix/linux-based OS are preferred), can handle reads from\nwhatever platform in the standard BAM format and implement a variety of\nfilters."
        },
        {
            "name": "py-biom-format",
            "description": "The BIOM file format (canonically pronounced biome) is designed to be a\ngeneral-use format for representing biological sample by observation\ncontingency tables."
        },
        {
            "name": "py-altair",
            "description": "Declarative statistical visualization library for Python"
        },
        {
            "name": "survey",
            "description": "Survey is a high level performance tool product from Trenza, Inc. The\nsurvey collector/analytics framework is a new generation, high level,\nlightweight multiplatform Linux tool set that targets metric collection\nfor high level performance analysis of applications running on both\nsingle node and on large scale platforms, including the Cray platforms.\nThe collector is designed to work on sequential, MPI, OpenMP, and hybrid\ncodes and directly leverages several interfaces available for tools\ninside current MPI implementations including: MPICH, MVAPICH, MPT, and\nOpenMPI. It also supports multiple architectures and has been tested on\nmachines based on Intel, AMD, ARM, and IBM P8/9 processors and\nintegrated GPUs. Survey is a licensed product with the source not openly\navailable. To access the survey source and build with spack please\ncontact: Trenza Inc. via: dmont@trenzasynergy.com or\njeg@trenzasynergy.com"
        },
        {
            "name": "py-rsatoolbox",
            "description": "Representational Similarity Analysis (RSA) in Python."
        },
        {
            "name": "py-cnvkit",
            "description": "Copy number variation toolkit for high-throughput sequencing."
        },
        {
            "name": "py-geopandas",
            "description": "GeoPandas is an open source project to make working with geospatial data\nin python easier. GeoPandas extends the datatypes used by pandas to\nallow spatial operations on geometric types. Geometric operations are\nperformed by shapely. Geopandas further depends on fiona for file access\nand descartes and matplotlib for plotting."
        },
        {
            "name": "py-nilearn",
            "description": "Statistical learning for neuroimaging in Python."
        },
        {
            "name": "py-xgboost",
            "description": "XGBoost is an optimized distributed gradient boosting library designed\nto be highly efficient, flexible and portable."
        },
        {
            "name": "busco",
            "description": "Assesses genome assembly and annotation completeness with Benchmarking\nUniversal Single-Copy Orthologs"
        },
        {
            "name": "py-petastorm",
            "description": "Petastorm is a library enabling the use of Parquet storage from\nTensorflow, Pytorch, and other Python-based ML training frameworks."
        },
        {
            "name": "py-anndata",
            "description": "anndata is a Python package for handling annotated data matrices in\nmemory and on disk, positioned between pandas and xarray."
        },
        {
            "name": "py-pybids",
            "description": "bids: interface with datasets conforming to BIDS"
        },
        {
            "name": "py-salib",
            "description": "Python implementations of commonly used sensitivity analysis methods."
        },
        {
            "name": "py-keras",
            "description": "Deep Learning for humans. Keras is a deep learning API written in\nPython, running on top of the machine learning platform TensorFlow. It\nwas developed with a focus on enabling fast experimentation. Being able\nto go from idea to result as fast as possible is key to doing good\nresearch."
        },
        {
            "name": "met",
            "description": "Statistical tool that matches up grids with either gridded analyses or\npoint observations and applies configurable methods to compute\nstatistics and diagnostics"
        },
        {
            "name": "py-carputils",
            "description": "The carputils framework for running simulations with the openCARP\nsoftware."
        },
        {
            "name": "py-astropy",
            "description": "The Astropy Project is a community effort to develop a single core\npackage for Astronomy in Python and foster interoperability between\nPython astronomy packages."
        },
        {
            "name": "py-matminer",
            "description": "Matminer is a library for performing data mining in the field of\nmaterials science."
        },
        {
            "name": "py-openmc",
            "description": "OpenMC is a community-developed Monte Carlo neutron and photon transport\nsimulation code. It is capable of performing fixed source, k-eigenvalue,\nand subcritical multiplication calculations on models built using either\na constructive solid geometry or CAD representation. OpenMC supports\nboth continuous-energy and multigroup transport. The continuous-energy\nparticle interaction data is based on a native HDF5 format that can be\ngenerated from ACE files produced by NJOY. Parallelism is enabled via a\nhybrid MPI and OpenMP programming model."
        },
        {
            "name": "roary",
            "description": "Rapid large-scale prokaryote pan genome analysis"
        },
        {
            "name": "py-lifelines",
            "description": "Survival analysis was originally developed and applied heavily by the\nactuarial and medical community. Its purpose was to answer *why do\nevents occur now versus later* under uncertainty (where *events* might\nrefer to deaths, disease remission, etc.). *lifelines* is a pure Python\nimplementation of the best parts of survival analysis."
        },
        {
            "name": "py-arcgis",
            "description": "ArcGIS API for Python."
        },
        {
            "name": "py-alphafold",
            "description": "AlphaFold is an AI system developed by DeepMind that predicts a\nprotein's 3D structure from its amino acid sequence. It regularly\nachieves accuracy competitive with experiment."
        },
        {
            "name": "cradl",
            "description": "The CRADL proxy application captured performance metrics during\ninference on data from multiphysics codes, specifically ALE\nhydrodynamics codes."
        },
        {
            "name": "py-ax-platform",
            "description": "Adaptive experimentation is the machine-learning guided process of\niteratively exploring a (possibly infinite) parameter space in order to\nidentify optimal configurations in a resource-efficient manner. Ax\ncurrently supports Bayesian optimization and bandit optimization as\nexploration strategies. Bayesian optimization in Ax is powered by\nBoTorch, a modern library for Bayesian optimization research built on\nPyTorch."
        },
        {
            "name": "py-cufflinks",
            "description": "Productivity Tools for Plotly + Pandas. This library binds the power of\nplotly with the flexibility of pandas for easy plotting."
        },
        {
            "name": "py-inference-schema",
            "description": "This package is intended to provide a uniform schema for common machine\nlearning applications, as well as a set of decorators that can be used\nto aid in web based ML prediction applications."
        },
        {
            "name": "py-neurokit2",
            "description": "The Python Toolbox for Neurophysiological Signal Processing. This\npackage is the continuation of NeuroKit 1. It's a user-friendly package\nproviding easy access to advanced biosignal processing routines.\nResearchers and clinicians without extensive knowledge of programming or\nbiomedical signal processing can analyze physiological data with only\ntwo lines of code."
        },
        {
            "name": "mlperf-deepcam",
            "description": "PyTorch implementation for the climate segmentation benchmark, based on\nthe Exascale Deep Learning for Climate Analytics"
        },
        {
            "name": "py-scikit-learn",
            "description": "A set of python modules for machine learning and data mining."
        },
        {
            "name": "gptune",
            "description": "GPTune is an autotuning framework that relies on multitask and transfer\nlearnings to help solve the underlying black-box optimization problem\nusing Bayesian optimization methodologies."
        },
        {
            "name": "py-statsmodels",
            "description": "Statistical computations and models for use with SciPy"
        },
        {
            "name": "py-pyani",
            "description": "pyani is a Python3 module that provides support for calculating average\nnucleotide identity (ANI) and related measures for whole genome\ncomparisons, and rendering relevant graphical summary output. Where\navailable, it takes advantage of multicore systems, and can integrate\nwith SGE/OGE-type job schedulers for the sequence comparisons."
        },
        {
            "name": "py-sdv",
            "description": "The Synthetic Data Vault (SDV) is a Synthetic Data Generation ecosystem\nof libraries that allows users to easily learn single-table, multi-table\nand timeseries datasets to later on generate new Synthetic Data that has\nthe same format and statistical properties as the original dataset."
        },
        {
            "name": "py-mizani",
            "description": "Mizani is a scales package for graphics. It is based on Hadley Wickham's\nScales package."
        },
        {
            "name": "py-cmseq",
            "description": "CMSeq is a set of commands to provide an interface to .bam files for\ncoverage and sequence consensus."
        },
        {
            "name": "py-ipyrad",
            "description": "An interactive toolkit for assembly and analysis of restriction-site\nassociated genomic data sets (e.g., RAD, ddRAD, GBS) for population\ngenetic and phylogenetic studies."
        },
        {
            "name": "py-pymatgen",
            "description": "Python Materials Genomics is a robust materials analysis code that\ndefines core object representations for structures and molecules with\nsupport for many electronic structure codes. It is currently the core\nanalysis code powering the Materials Project."
        },
        {
            "name": "py-phylophlan",
            "description": "PhyloPhlAn 3.0 is an integrated pipeline for large-scale phylogenetic\nprofiling of genomes and metagenomes."
        },
        {
            "name": "amr-wind",
            "description": "AMR-Wind is a massively parallel, block-structured adaptive-mesh,\nincompressible flow sover for wind turbine and wind farm simulations."
        },
        {
            "name": "py-niworkflows",
            "description": "Common workflows for MRI (anatomical, functional, diffusion, etc)"
        },
        {
            "name": "py-pauvre",
            "description": "pauvre: plotting package designed for nanopore and PacBio long reads"
        },
        {
            "name": "py-geeup",
            "description": "Simple Client for Earth Engine Uploads with Selenium Support."
        },
        {
            "name": "py-sdmetrics",
            "description": "The SDMetrics library provides a set of dataset-agnostic tools for\nevaluating the quality of a synthetic database by comparing it to the\nreal database that it is modeled after."
        },
        {
            "name": "py-dh-scikit-optimize",
            "description": "A Modified version of scikit-optimize a Sequential model-based\noptimization toolbox for DeepHyper. Scikit-Optimize, or skopt, is a\nsimple and efficient library to minimize (very) expensive and noisy\nblack-box functions. It implements several methods for sequential model-\nbased optimization. skopt aims to be accessible and easy to use in many\ncontexts. The library is built on top of NumPy, SciPy and Scikit-Learn."
        },
        {
            "name": "py-elephant",
            "description": "Elephant is a package for analysis of electrophysiology data in Python"
        },
        {
            "name": "geopm",
            "description": "GEOPM is an extensible power management framework targeting HPC. The\nGEOPM package provides libgeopm, libgeopmpolicy and applications\ngeopmctl and geopmpolicy, as well as tools for postprocessing. GEOPM is\ndesigned to be extended for new control algorithms and new hardware\npower management features via its plugin infrastructure. Note: GEOPM\ninterfaces with hardware using Model Specific Registers (MSRs). For\npropper usage make sure MSRs are made available directly or via the msr-\nsafe kernel module by your administrator."
        },
        {
            "name": "py-cinemasci",
            "description": "A set of python tools for reading, writing and viewing Cinema databases"
        }
    ]
}