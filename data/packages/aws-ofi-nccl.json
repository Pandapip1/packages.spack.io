{
    "name": "aws-ofi-nccl",
    "aliases": [],
    "versions": [
        {
            "name": "master",
            "branch": "master"
        }
    ],
    "latest_version": "master",
    "build_system": "AutotoolsPackage",
    "conflicts": [
        {
            "name": "platform=windows",
            "spec": "build_system=autotools",
            "description": "None"
        }
    ],
    "variants": [
        {
            "name": "build_system",
            "default": "autotools",
            "description": "Build systems supported by the package"
        },
        {
            "name": "trace",
            "default": false,
            "description": "Enable printing trace messages"
        },
        {
            "name": "tests",
            "default": false,
            "description": "Build tests"
        }
    ],
    "homepage": "https://github.com/aws/aws-ofi-nccl",
    "maintainers": [
        "bvanessen"
    ],
    "patches": [],
    "resources": [],
    "description": "AWS OFI NCCL is a plug-in which enables EC2 developers to use libfabric\nas a network provider while running NVIDIA's NCCL based applications.\n",
    "dependencies": [
        {
            "name": "gnuconfig",
            "description": "The GNU config.guess and config.sub scripts versioned by timestamp.\nThis package can be used as a build dependency for autotools packages\nthat ship a tarball with outdated config.guess and config.sub files."
        },
        {
            "name": "gmake",
            "description": "GNU Make is a tool which controls the generation of executables and\nother non-source files of a program from the program's source files."
        },
        {
            "name": "libfabric",
            "description": "The Open Fabrics Interfaces (OFI) is a framework focused on exporting\nfabric communication services to applications."
        },
        {
            "name": "cuda",
            "description": "CUDA is a parallel computing platform and programming model invented by\nNVIDIA. It enables dramatic increases in computing performance by\nharnessing the power of the graphics processing unit (GPU). Note: This\npackage does not currently install the drivers necessary to run CUDA.\nThese will need to be installed manually. See:\nhttps://docs.nvidia.com/cuda/ for details."
        },
        {
            "name": "nccl",
            "description": "Optimized primitives for collective multi-GPU communication."
        },
        {
            "name": "mpi",
            "description": "An open source Message Passing Interface implementation. The Open MPI\nProject is an open source Message Passing Interface implementation that\nis developed and maintained by a consortium of academic, research, and\nindustry partners. Open MPI is therefore able to combine the expertise,\ntechnologies, and resources from all across the High Performance\nComputing community in order to build the best MPI library available.\nOpen MPI offers advantages for system and software vendors, application\ndevelopers and computer science researchers."
        },
        {
            "name": "autoconf",
            "description": "Autoconf -- system configuration part of autotools"
        },
        {
            "name": "automake",
            "description": "Automake -- make file builder part of autotools"
        },
        {
            "name": "libtool",
            "description": "libtool -- library building part of autotools."
        }
    ],
    "dependent_to": []
}