{
    "name": "py-torch-spline-conv",
    "aliases": [],
    "versions": [
        {
            "name": "1.2.0",
            "sha256": "ab8da41357c8a4785662366655bb6dc5e84fd0e938008194955409aefe535009"
        }
    ],
    "build_system": "PythonPackage",
    "conflicts": [],
    "variants": [
        {
            "name": "cuda",
            "default": false,
            "description": "Enable CUDA support"
        }
    ],
    "homepage": "https://github.com/rusty1s/pytorch_spline_conv",
    "maintainers": [
        "adamjstewart"
    ],
    "patches": [],
    "resources": [],
    "description": "This is a PyTorch implementation of the spline-based convolution\noperator of SplineCNN.\n",
    "dependencies": [
        {
            "name": "python",
            "description": "The Python programming language."
        },
        {
            "name": "py-setuptools",
            "description": "A Python utility that aids in the process of downloading, building,\nupgrading, installing, and uninstalling Python packages."
        },
        {
            "name": "py-pytest-runner",
            "description": "Invoke py.test as distutils command with dependency resolution."
        },
        {
            "name": "py-torch",
            "description": "Tensors and Dynamic neural networks in Python with strong GPU\nacceleration."
        }
    ],
    "dependent_to": [
        {
            "name": "py-torch-geometric",
            "description": "PyTorch Geometric (PyG) is a geometric deep learning extension library\nfor PyTorch. It consists of various methods for deep learning on graphs\nand other irregular structures, also known as geometric deep learning,\nfrom a variety of published papers. In addition, it consists of an easy-\nto-use mini-batch loader for many small and single giant graphs, multi\ngpu-support, a large number of common benchmark datasets (based on\nsimple interfaces to create your own), and helpful transforms, both for\nlearning on arbitrary graphs as well as on 3D meshes or point clouds."
        }
    ]
}