{
    "name": "py-transformer-engine",
    "aliases": [],
    "versions": [
        {
            "name": "1.4",
            "tag": "v1.4"
        },
        {
            "name": "main",
            "branch": "main"
        }
    ],
    "latest_version": "1.4",
    "build_system": "PythonPackage",
    "conflicts": [],
    "variants": [
        {
            "name": "build_system",
            "default": "python_pip",
            "description": "Build systems supported by the package"
        },
        {
            "name": "userbuffers",
            "default": true,
            "description": "Enable userbuffers, this option needs MPI."
        }
    ],
    "homepage": "https://github.com/NVIDIA/TransformerEngine",
    "maintainers": [
        "aurianer"
    ],
    "patches": [],
    "resources": [],
    "description": " A library for accelerating Transformer models on NVIDIA GPUs, including\nfp8 precision on Hopper GPUs.\n",
    "dependencies": [
        {
            "name": "cmake",
            "description": "A cross-platform, open-source build system. CMake is a family of tools\ndesigned to build, test and package software."
        },
        {
            "name": "mpi",
            "description": "MVAPICH2-X is the advanced version of the MVAPICH2 MPI library with\nenhanced features (UMR, ODP, DC, Core-Direct, SHARP, XPMEM), OSU INAM\n(InifniBand Network Monitoring and Analysis),PGAS (OpenSHMEM, UPC,\nUPC++, and CAF), and MPI+PGAS programming models with unified\ncommunication runtime. MVAPICH2-X is not installable from source and is\nonly available through a binary mirror. If you do not find the binary\nyou're looking for, send us an email at mvapich@cse.ohio-state.edu. The\nbinary mirror url is: http://mvapich.cse.ohio-\nstate.edu/download/mvapich/spack-mirror/mvapich2x/"
        },
        {
            "name": "py-accelerate",
            "description": "A simple way to train and use PyTorch models with multi-GPU, TPU, mixed-\nprecision."
        },
        {
            "name": "py-datasets",
            "description": "Datasets is a lightweight library providing two main features: one-line\ndataloaders for many public datasets and efficient data pre-processing."
        },
        {
            "name": "py-flash-attn",
            "description": "This package provides the official implementation of FlashAttention."
        },
        {
            "name": "py-importlib-metadata",
            "description": "Read metadata from Python packages."
        },
        {
            "name": "py-packaging",
            "description": "Core utilities for Python packages."
        },
        {
            "name": "py-pip",
            "description": "The PyPA recommended tool for installing Python packages."
        },
        {
            "name": "py-pydantic",
            "description": "Data validation and settings management using Python type hinting."
        },
        {
            "name": "py-setuptools",
            "description": "A Python utility that aids in the process of downloading, building,\nupgrading, installing, and uninstalling Python packages."
        },
        {
            "name": "py-torch",
            "description": "Tensors and Dynamic neural networks in Python with strong GPU\nacceleration."
        },
        {
            "name": "py-torchvision",
            "description": "Image and video datasets and models for torch deep learning."
        },
        {
            "name": "py-transformers",
            "description": "State-of-the-art Natural Language Processing for TensorFlow 2.0 and\nPyTorch"
        },
        {
            "name": "py-wheel",
            "description": "A built-package format for Python."
        },
        {
            "name": "python",
            "description": "The Python programming language."
        },
        {
            "name": "python-venv",
            "description": "A Spack managed Python virtual environment"
        }
    ],
    "dependent_to": []
}