{
    "name": "py-charm4py",
    "aliases": [],
    "versions": [
        {
            "name": "1.0",
            "sha256": "8ddb9f021b7379fde94b28c31f4ab6a60ced2c2a207a2d75ce57cb91b6be92bc"
        }
    ],
    "latest_version": "1.0",
    "build_system": "PythonPackage",
    "conflicts": [],
    "variants": [
        {
            "name": "build_system",
            "default": "python_pip",
            "description": "Build systems supported by the package"
        },
        {
            "name": "mpi",
            "default": true,
            "description": "build Charm++ library with the MPI instead of TCP communication layer"
        }
    ],
    "homepage": "https://charmpy.readthedocs.io",
    "maintainers": [
        "adamjstewart",
        "payerle"
    ],
    "patches": [
        {
            "owner": "builtin.py-charm4py",
            "sha256": "a17ab58858689615310bb412e1223f9e13dcba6b8e586b1d418cd56f82c236c9",
            "level": 1,
            "working_dir": ".",
            "relative_path": "py-charm4py.makefile.patch",
            "version": "@1.0"
        }
    ],
    "resources": [],
    "description": "Charm4py (Charm++ for Python) is a distributed computing and parallel\nprogramming framework for Python, for the productive development of\nfast, parallel and scalable applications. It is built on top of Charm++,\na C++ adaptive runtime system that has seen extensive use in the\nscientific and high-performance computing (HPC) communities across many\ndisciplines, and has been used to develop applications that run on a\nwide range of devices: from small multi-core devices up to the largest\nsupercomputers.\n",
    "dependencies": [
        {
            "name": "autoconf",
            "description": "Autoconf -- system configuration part of autotools"
        },
        {
            "name": "automake",
            "description": "Automake -- make file builder part of autotools"
        },
        {
            "name": "cuda",
            "description": "CUDA is a parallel computing platform and programming model invented by\nNVIDIA. It enables dramatic increases in computing performance by\nharnessing the power of the graphics processing unit (GPU). Note: This\npackage does not currently install the drivers necessary to run CUDA.\nThese will need to be installed manually. See:\nhttps://docs.nvidia.com/cuda/ for details."
        },
        {
            "name": "mpi",
            "description": "This is an earlier version of Intel parallel software development tools\nand has now been replaced by the Intel oneAPI Toolkits. LICENSE\nINFORMATION: By downloading and using this software, you agree to the\nterms and conditions of the software license agreements at\nhttps://intel.ly/393CijO."
        },
        {
            "name": "py-cffi",
            "description": "Foreign Function Interface for Python calling C code"
        },
        {
            "name": "py-cython",
            "description": "The Cython compiler for writing C extensions for the Python language."
        },
        {
            "name": "py-greenlet",
            "description": "Lightweight in-process concurrent programming"
        },
        {
            "name": "py-numpy",
            "description": "Fundamental package for array computing in Python."
        },
        {
            "name": "py-pip",
            "description": "The PyPA recommended tool for installing Python packages."
        },
        {
            "name": "py-setuptools",
            "description": "A Python utility that aids in the process of downloading, building,\nupgrading, installing, and uninstalling Python packages."
        },
        {
            "name": "py-wheel",
            "description": "A built-package format for Python."
        },
        {
            "name": "python",
            "description": "The Python programming language."
        }
    ],
    "dependent_to": []
}