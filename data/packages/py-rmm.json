{
    "name": "py-rmm",
    "aliases": [],
    "versions": [
        {
            "name": "0.15.0",
            "sha256": "599f97b95d169a90d11296814763f7e151a8a1e060ba10bc6c8f4684a5cd7972"
        }
    ],
    "latest_version": "0.15.0",
    "build_system": "PythonPackage",
    "conflicts": [],
    "variants": [
        {
            "name": "build_system",
            "default": "python_pip",
            "description": "Build systems supported by the package"
        }
    ],
    "homepage": "https://github.com/rapidsai/rmm",
    "maintainers": [
        "adamjstewart",
        "pradyunsg"
    ],
    "patches": [],
    "resources": [],
    "description": "RMM: RAPIDS Memory Manager. Achieving optimal performance in GPU-centric\nworkflows frequently requires customizing how host and device memory are\nallocated.\n",
    "dependencies": [
        {
            "name": "python",
            "description": "The Python programming language."
        },
        {
            "name": "py-pip",
            "description": "The PyPA recommended tool for installing Python packages."
        },
        {
            "name": "py-wheel",
            "description": "A built-package format for Python."
        },
        {
            "name": "py-setuptools",
            "description": "A Python utility that aids in the process of downloading, building,\nupgrading, installing, and uninstalling Python packages."
        },
        {
            "name": "py-cython",
            "description": "The Cython compiler for writing C extensions for the Python language."
        },
        {
            "name": "py-numba",
            "description": "NumPy aware dynamic Python compiler using LLVM"
        },
        {
            "name": "librmm",
            "description": "RMM: RAPIDS Memory Manager. Achieving optimal performance in GPU-centric\nworkflows frequently requires customizing how host and device memory are\nallocated."
        },
        {
            "name": "cuda",
            "description": "CUDA is a parallel computing platform and programming model invented by\nNVIDIA. It enables dramatic increases in computing performance by\nharnessing the power of the graphics processing unit (GPU). Note: This\npackage does not currently install the drivers necessary to run CUDA.\nThese will need to be installed manually. See:\nhttps://docs.nvidia.com/cuda/ for details."
        },
        {
            "name": "spdlog",
            "description": "Very fast, header only, C++ logging library"
        }
    ],
    "dependent_to": [
        {
            "name": "py-cudf",
            "description": "Built based on the Apache Arrow columnar memory format, cuDF is a GPU\nDataFrame library for loading, joining, aggregating, filtering, and\notherwise manipulating data."
        }
    ]
}