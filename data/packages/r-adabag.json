{
    "name": "r-adabag",
    "aliases": [],
    "versions": [
        {
            "name": "4.2",
            "sha256": "47019eb8cefc8372996fbb2642f64d4a91d7cedc192690a8d8be6e7e03cd3c81"
        },
        {
            "name": "4.1",
            "sha256": "ff938c36122cdf58a71a59a6bf79a3c7816966ee7cc4907c4a0a3c0732e3d028"
        }
    ],
    "latest_version": "4.2",
    "build_system": "RPackage",
    "conflicts": [],
    "variants": [
        {
            "name": "build_system",
            "default": "generic",
            "description": "Build systems supported by the package"
        }
    ],
    "homepage": "https://cloud.r-project.org/package=adabag",
    "maintainers": [],
    "patches": [],
    "resources": [],
    "description": "Applies Multiclass AdaBoost.M1, SAMME and Bagging. It implements Freund\nand Schapire's Adaboost.M1 algorithm and Breiman's Bagging algorithm\nusing classification trees as individual classifiers. Once these\nclassifiers have been trained, they can be used to predict on new data.\nAlso, cross validation estimation of the error can be done. Since\nversion 2.0 the function margins() is available to calculate the margins\nfor these classifiers. Also a higher flexibility is achieved giving\naccess to the rpart.control() argument of 'rpart'. Four important new\nfeatures were introduced on version 3.0, AdaBoost-SAMME (Zhu et al.,\n2009) is implemented and a new function errorevol() shows the error of\nthe ensembles as a function of the number of iterations. In addition,\nthe ensembles can be pruned using the option 'newmfinal' in the\npredict.bagging() and predict.boosting() functions and the posterior\nprobability of each class for observations can be obtained. Version 3.1\nmodifies the relative importance measure to take into account the gain\nof the Gini index given by a variable in each tree and the weights of\nthese trees. Version 4.0 includes the margin-based ordered aggregation\nfor Bagging pruning (Guo and Boukir, 2013) and a function to auto prune\nthe 'rpart' tree. Moreover, three new plots are also available\nimportanceplot(), plot.errorevol() and plot.margins(). Version 4.1\nallows to predict on unlabeled data. Version 4.2 includes the parallel\ncomputation option for some of the functions.\n",
    "dependencies": [
        {
            "name": "r",
            "description": "R is 'GNU S', a freely available language and environment for\nstatistical computing and graphics which provides a wide variety of\nstatistical and graphical techniques: linear and nonlinear modelling,\nstatistical tests, time series analysis, classification, clustering,\netc. Please consult the R project homepage for further information."
        },
        {
            "name": "r-caret",
            "description": "Classification and Regression Training. Misc functions for training and\nplotting classification and regression models."
        },
        {
            "name": "r-doparallel",
            "description": "Foreach Parallel Adaptor for the 'parallel' Package. Provides a parallel\nbackend for the %dopar% function using the parallel package."
        },
        {
            "name": "r-foreach",
            "description": "Provides Foreach Looping Construct. Support for the foreach looping\nconstruct. Foreach is an idiom that allows for iterating over elements\nin a collection, without the use of an explicit loop counter. This\npackage in particular is intended to be used for its return value,\nrather than for its side effects. In that sense, it is similar to the\nstandard lapply function, but doesn't require the evaluation of a\nfunction. Using foreach without side effects also facilitates executing\nthe loop in parallel."
        },
        {
            "name": "r-mlbench",
            "description": "Machine Learning Benchmark Problems. A collection of artificial and\nreal-world machine learning benchmark problems, including, e.g., several\ndata sets from the UCI repository."
        },
        {
            "name": "r-rpart",
            "description": "Recursive Partitioning and Regression Trees. Recursive partitioning for\nclassification, regression and survival trees. An implementation of most\nof the functionality of the 1984 book by Breiman, Friedman, Olshen and\nStone."
        }
    ],
    "dependent_to": [
        {
            "name": "r-rminer",
            "description": "Data Mining Classification and Regression Methods. Facilitates the use\nof data mining algorithms in classification and regression (including\ntime series forecasting) tasks by presenting a short and coherent set of\nfunctions. Versions: 1.4.6 / 1.4.5 / 1.4.4 new automated machine\nlearning (AutoML) and ensembles, via improved fit(), mining() and\nmparheuristic() functions, and new categorical preprocessing, via\nimproved delevels() function; 1.4.3 new metrics (e.g., macro precision,\nexplained variance), new \"lssvm\" model and improved mparheuristic()\nfunction; 1.4.2 new \"NMAE\" metric, \"xgboost\" and \"cv.glmnet\" models (16\nclassification and 18 regression models); 1.4.1 new tutorial and more\nrobust version; 1.4 - new classification and regression models, with a\ntotal of 14 classification and 15 regression methods, including:\nDecision Trees, Neural Networks, Support Vector Machines, Random\nForests, Bagging and Boosting; 1.3 and 1.3.1 - new classification and\nregression metrics; 1.2 - new input importance methods via improved\nImportance() function; 1.0 - first version."
        }
    ]
}